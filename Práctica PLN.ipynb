{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Procesamiento de Lenguaje Natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alumna: Daniela Olivas Mendoza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, tomarémos un sitio web y analizarémos el texto para ver que trata la pag. web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería Urllib ayuda a obtener los datos de la pag. web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "response = urllib.request.urlopen('https://en.wikipedia.org/wiki/SpaceX')\n",
    "html = response.read()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilzarémos Beautiful Soup, la cual es una librería en python para extraer datos de archivos HTML y XML. Vamos a utilizar esta librería para limpiar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'htmlSlib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuenta la frecuencia de las palabras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK ofrece una función FreqDist() que hace el trabajo por nosotros. Además de esto, se eliminan las palabras (a, at, the, for, etc.)(Stop Words), ya que no son necesarias para el conteo de la frecuencia en las palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, trazamos el gráfico de las palabras que aparecen con más frecuencia en la pag web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sr = stopwords.words('english')\n",
    "clean_tokens = tokens[:]\n",
    "for token in tokens:\n",
    "    if token in stopwords.words('english'):\n",
    "        clean_tokers.remove(token)\n",
    "freq = nltk.freqDist(clean_tokens)\n",
    "for key, val in freq.items():\n",
    "            print(str(key) + ':' + str(val))\n",
    "freq.plot(20, comulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
