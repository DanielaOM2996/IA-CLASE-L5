{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica: Detección de lenguaje usanod NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alumna: Daniela Olivas Mendoza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python es uno de los lenguajes de programas más potentes y populares. Como hemos visto hasta el día de hoy, se puede utilizar de muchas formas. Entre una de estas formas, se incluye la detección de idiomas. Es aquí en donde entran los algoritmos de PLN.\n",
    "\n",
    "Los algoritmos de PLN tiene que modificarse para diferentes corpus y de acuerdo con la gramática de diferentes idiomas. De acuerdo con el idioma que se esté utilizando para realizar PLN, es el software o librerías que se debe seleccionar. Por ejemplo, NLTK es la librería de procesamiento de lenguaje natural más utilizada para el idioma inglés en Ptyhon. Sin embargo, FreeLing es de las mejores alternativas cuando estamos trabajando con español.\n",
    "\n",
    "La eficiencia del procesamiento de lenguaje natural depende de varios factores. Un modelo como una calidad superior para el análisi de texto debe incluir lo siguiente:\n",
    "\n",
    "## 1. Extracción del texto:\n",
    "El texto puede extraerse mediante desde una página o datos web, importándolos en un formato particular, tomándolo desde una base de datos a un API.\n",
    "\n",
    "## 2. Identificación del texto.\n",
    "Es el proceso de separación de texto relevante o de interés del texto que nos añade ruido al análisis.\n",
    "\n",
    "## 3. Procesamiento de Lenguaje Natural (PLN).\n",
    "Es el conjunto de algoritmos que admiten el procesamiento de diferentes idiomas o lenguajes.\n",
    "\n",
    "## 4. Aprendizaje automático.\n",
    "Es un paso esencial para lograr objetivos como la colaboración, el análisi de sentimientos y agrupación.\n",
    "\n",
    "## Combinación de Python y NLTK para la detección de lenguaje.\n",
    "La mayoría de las personas utilizan motores de búsqueda y redes sociales. Los cuales muestran en diferentes lenguajes, entre ellos, el español e inglés.\n",
    "\n",
    "Para lograr este proceso, un texto inadecuado debe examinarse bien, lo que da como resultado el contenido por estos motores y redes sociales.\n",
    "\n",
    "Existen diferentes maneras de lograr este objetivo, la forma más sencilla de hacerlo es mediante el enfoque basado en \"stop words\".\n",
    "\n",
    "\"Stopword\" se usa en el procesamiento de lenguaje natural para mencionar palabras que se deben filtrar del texto antes de que tenga lugar cualquier tipo de procesamiento.\n",
    "\n",
    "\n",
    "Ahora tenemos un texto para detectar el idioma. El paso básico es Tokenizar el texto dado una lista de \"palabras\" y \"tokens\", utilizando un enfoque que depende de los requerimientos.\n",
    "\n",
    "## El siguiente ejemplo de detección de lenguaje utiliza NLTK y Python.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b25b2ecc0b46>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-b25b2ecc0b46>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from nltk import\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk import\n",
    "from nltk.corpus import\n",
    "\n",
    "def lang_ratio(import):\n",
    "    lang_ratio = {}\n",
    "    tokens = wordpunct_tokenize(import)\n",
    "    words = [word.lower() for word in tokens]\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        words_set = set(words)\n",
    "        common_elements = words_set.intersection(stopwords_set)\n",
    "        lang_ratio[language] = len(common_elements)\n",
    "    return lang_ratio\n",
    "\n",
    "def detect_language(input):\n",
    "    ratios = lang_ratio(input)\n",
    "    language = max(ratios, key=ratios.get)\n",
    "    return language\n",
    "\n",
    "input1 = \"Hello, my name is Daniela Olivas\"\n",
    "input2 = \"Hola, mi nombre es Daniela Olivas\"\n",
    "input3 = \"Bonjour, mon nom est Daniela Olivas\"\n",
    "input4 = \"Hallo, mein Name ist Daniela Olivas\"\n",
    "\n",
    "language = detect_language(input1)\n",
    "print (\"Cadena de texto:\" + input1 + \"\\t Lenguaje: \" + language)\n",
    "\n",
    "language = detect_language(input2)\n",
    "print (\"\\n\" + \"Cadena de texto:\" + input2 + \"\\t Lenguaje: \" + language)\n",
    "\n",
    "language = detect_language(input3)\n",
    "print (\"\\n\" + \"Cadena de texto:\" + input3 + \"\\t Lenguaje: \" + language)\n",
    "\n",
    "language = detect_language(input4)\n",
    "print (\"\\n\" + \"Cadena de texto:\" + input4 + \"\\t Lenguaje: \" + language)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
